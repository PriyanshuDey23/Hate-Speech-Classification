{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Hate-Speech-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Hate-Speech-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    Transformed_filename: Path\n",
    "    Data_dir: str\n",
    "    Id: str\n",
    "    Axis: int\n",
    "    Inplace: bool\n",
    "    Drop_Columns: list\n",
    "    Class: str\n",
    "    Label: str\n",
    "    Tweet: str\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration manager\n",
    "from Hate_Speech_Classification.constrants import * # Import Everything\n",
    "from Hate_Speech_Classification.utils.common import read_yaml,create_directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,  # Return Box Type  # Ctrl+click to check the file path\n",
    "            params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "            self.config=read_yaml(config_filepath)\n",
    "            self.params=read_yaml(params_filepath)\n",
    "\n",
    "            # From common.py\n",
    "            create_directories([self.config.artifacts_root]) # I can call using the key name using Box Type\n",
    "\n",
    "    def get_data_Transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir]) \n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            Transformed_filename=config.Transformed_filename,\n",
    "            Data_dir=config.Data_dir,\n",
    "            Id=config.Id,\n",
    "            Axis=config.Axis,\n",
    "            Inplace=config.Inplace,\n",
    "            Drop_Columns=config.Drop_Columns,\n",
    "            Class=config.Class,\n",
    "            Label=config.Label,\n",
    "            Tweet=config.Tweet\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Hate_Speech_Classification.Logging import logging \n",
    "from Hate_Speech_Classification.Exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "\n",
    "    def imbalance_data_cleaning(self):\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Entered into the imbalance_data_cleaning function\")\n",
    "            imbalance_data=pd.read_csv(\"artifacts\\data_ingestion\\imbalanced_data.csv\")\n",
    "            imbalance_data.drop(self.config.Id,axis=self.config.Axis , inplace = self.config.Inplace)\n",
    "            logging.info(f\"Exited the imbalance data_cleaning function and returned imbalance data {imbalance_data}\")\n",
    "            return imbalance_data \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys) from e \n",
    "\n",
    "\n",
    "\n",
    "    def raw_data_cleaning(self):\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Entered into the raw_data_cleaning function\")\n",
    "            raw_data = pd.read_csv(\"artifacts/data_ingestion/raw_data.csv\")\n",
    "            raw_data.drop(self.config.Drop_Columns,axis = self.config.Axis,\n",
    "            inplace = self.config.Inplace)\n",
    "\n",
    "\n",
    "            raw_data[raw_data[self.config.Class]==0][self.config.Class]=1\n",
    "\n",
    "            # replace the value of 0 to 1\n",
    "            raw_data[self.config.Class].replace({0:1},inplace=True)\n",
    "\n",
    "            # Let's replace the value of 2 to 0.\n",
    "            raw_data[self.config.Class].replace({2:0}, inplace = True)\n",
    "\n",
    "            # Let's change the name of the 'class' to label\n",
    "            raw_data.rename(columns={self.config.Class:self.config.Label},inplace =True)\n",
    "            logging.info(f\"Exited the raw_data_cleaning function and returned the raw_data {raw_data}\")\n",
    "            return raw_data\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys) from e\n",
    "\n",
    "\n",
    "\n",
    "    def concat_dataframe(self):\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Entered into the concat_dataframe function\")\n",
    "            # Let's concatinate both the data into a single data frame.\n",
    "            frame = [self.raw_data_cleaning(), self.imbalance_data_cleaning()]\n",
    "            df = pd.concat(frame)\n",
    "            print(df.head())\n",
    "            logging.info(f\"returned the concatinated dataframe {df}\")\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e\n",
    "\n",
    "\n",
    "\n",
    "    def concat_data_cleaning(self, words):\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Entered into the concat_data_cleaning function\")\n",
    "            stemmer = nltk.SnowballStemmer(\"english\")\n",
    "            stopword = set(stopwords.words('english'))\n",
    "            \n",
    "            words = str(words).lower()\n",
    "            words = re.sub('\\[.*?\\]', '', words)\n",
    "            words = re.sub('https?://\\S+|www\\.\\S+', '', words)\n",
    "            words = re.sub('<.*?>+', '', words)\n",
    "            words = re.sub('[%s]' % re.escape(string.punctuation), '', words)\n",
    "            words = re.sub('\\n', '', words)\n",
    "            words = re.sub('\\w*\\d\\w*', '', words)\n",
    "\n",
    "            # Remove stopwords and apply stemming\n",
    "            words = [word for word in words.split() if word not in stopword]\n",
    "            words = \" \".join([stemmer.stem(word) for word in words])\n",
    "\n",
    "            logging.info(\"Exited the concat_data_cleaning function\")\n",
    "            return words\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e\n",
    "\n",
    "\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            logging.info(\"Entered the initiate_data_transformation method of Data transformation class\")\n",
    "            \n",
    "            # Cleaning and transforming data\n",
    "            df = self.concat_dataframe()\n",
    "            df[self.config.Tweet] = df[self.config.Tweet].apply(self.concat_data_cleaning)\n",
    "\n",
    "            # Save the transformed data\n",
    "            os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "            df.to_csv(self.config.Transformed_filename, index=False, header=True)\n",
    "\n",
    "            # Return the DataTransformationConfig object\n",
    "            data_transformation_artifact = DataTransformationConfig(\n",
    "                root_dir=self.config.root_dir,\n",
    "                Transformed_filename=self.config.Transformed_filename,\n",
    "                Data_dir=self.config.Data_dir,\n",
    "                Id=self.config.Id,\n",
    "                Axis=self.config.Axis,\n",
    "                Inplace=self.config.Inplace,\n",
    "                Drop_Columns=self.config.Drop_Columns,\n",
    "                Class=self.config.Class,\n",
    "                Label=self.config.Label,\n",
    "                Tweet=self.config.Tweet\n",
    "            )\n",
    "            logging.info(\"Returning the DataTransformationArtifacts\")\n",
    "            return data_transformation_artifact\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6508\\250299221.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_data[raw_data[self.config.Class]==0][self.config.Class]=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              tweet\n",
      "0      0  !!! RT @mayasolovely: As a woman you shouldn't...\n",
      "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
      "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
      "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
      "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "from Hate_Speech_Classification.Logging import logging \n",
    "from Hate_Speech_Classification.Exception import CustomException\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_Transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation_artifact = data_transformation.initiate_data_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
