{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Hate-Speech-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Hate-Speech-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    x_test_data_path: Path\n",
    "    x_train_data_path: Path\n",
    "    y_test_data_path: Path\n",
    "    Random_state: int\n",
    "    Epoch: int\n",
    "    Batch_size: int\n",
    "    Validation_Split: float\n",
    "    Max_Words: int\n",
    "    Max_Len: int\n",
    "    Loss: str\n",
    "    Metrics: list\n",
    "    Activation: str\n",
    "    test_size: float\n",
    "    layers: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration manager\n",
    "from Hate_Speech_Classification.constrants import * # Import Everything\n",
    "from Hate_Speech_Classification.utils.common import read_yaml,create_directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,  # Return Box Type  # Ctrl+click to check the file path\n",
    "            params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "            self.config=read_yaml(config_filepath)\n",
    "            self.params=read_yaml(params_filepath)\n",
    "\n",
    "            # From common.py\n",
    "            create_directories([self.config.artifacts_root]) # I can call using the key name using Box Type\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        \n",
    "        create_directories([config['root_dir']])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            trained_model_path=config.trained_model_path,\n",
    "            x_test_data_path=config.x_test_data_path,\n",
    "            x_train_data_path=config.x_train_data_path,\n",
    "            y_test_data_path=config.y_test_data_path,\n",
    "            Random_state=params.Random_state,\n",
    "            Epoch=params.Epoch,\n",
    "            Batch_size=params.Batch_size,\n",
    "            Validation_Split=params.Validation_Split,\n",
    "            Max_Words=params.Max_Words,\n",
    "            Max_Len=params.Max_Len,\n",
    "            Loss=params.Loss,\n",
    "            Metrics=params.Metrics,\n",
    "            Activation=params.Activation,\n",
    "            test_size=params.test_size,\n",
    "            layers=params.layers\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from Hate_Speech_Classification.Logging import logging\n",
    "from Hate_Speech_Classification.constrants import * # Import Everything\n",
    "from Hate_Speech_Classification.Exception import CustomException\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM,Activation,Dense,Dropout,Input,Embedding,SpatialDropout1D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def spliting_data(self):\n",
    "        try:\n",
    "            logging.info(\"Entered the spliting_data function\")\n",
    "            df = pd.read_csv(\"artifacts/data_transformation/final.csv\", index_col=False)\n",
    "            logging.info(\"Splitting the data into x and y\")\n",
    "            x = df[\"tweet\"]\n",
    "            y = df[\"label\"]\n",
    "\n",
    "            # Handle NaN and non-string values in the 'tweet' column\n",
    "            logging.info(\"Checking and handling NaN or float values in the text data\")\n",
    "            x = x.fillna('')  # Replace NaN with empty strings\n",
    "            x = x.apply(lambda text: str(text))  # Convert any float or other types to strings\n",
    "\n",
    "            # Optional: Convert text to lowercase\n",
    "            x = x.apply(lambda text: text.lower())\n",
    "\n",
    "            logging.info(\"Applying train_test_split on the data\")\n",
    "            x_train, x_test, y_train, y_test = train_test_split(\n",
    "                x, y, test_size=self.config.test_size, random_state=self.config.Random_state\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Train size: {len(x_train)}, Test size: {len(x_test)}\")\n",
    "            return x_train, x_test, y_train, y_test\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "    def tokenizing(self, x_train):\n",
    "        try:\n",
    "            logging.info(\"Tokenizing the data\")\n",
    "            tokenizer = Tokenizer(num_words=self.config.Max_Words)\n",
    "            tokenizer.fit_on_texts(x_train)\n",
    "            sequences = tokenizer.texts_to_sequences(x_train)\n",
    "            sequences_matrix = pad_sequences(sequences, maxlen=self.config.Max_Len)\n",
    "            return sequences_matrix, tokenizer\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_model(self):\n",
    "        try:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(input_dim=self.config.Max_Words, output_dim=self.config.layers, input_length=self.config.Max_Len))\n",
    "            model.add(SpatialDropout1D(0.2))\n",
    "            model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "            model.add(Dense(1, activation=self.config.Activation))\n",
    "            model.summary()\n",
    "            model.compile(loss=self.config.Loss, optimizer=RMSprop(), metrics=self.config.Metrics)\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initiate_model_trainer(self):\n",
    "        try:\n",
    "            logging.info(\"Initiating model training\")\n",
    "            x_train, x_test, y_train, y_test = self.spliting_data()\n",
    "\n",
    "            model = self.get_model()\n",
    "\n",
    "            sequences_matrix, tokenizer = self.tokenizing(x_train)\n",
    "\n",
    "            logging.info(\"Training the model\")\n",
    "            model.fit(sequences_matrix, y_train, batch_size=self.config.Batch_size, epochs=self.config.Epoch, validation_split=self.config.Validation_Split)\n",
    "\n",
    "            logging.info(\"Saving tokenizer and model\")\n",
    "            with open('tokenizer.pickle', 'wb') as handle:\n",
    "                pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "            model.save(self.config.trained_model_path)\n",
    "\n",
    "            logging.info(\"Saving test and train data\")\n",
    "            x_test.to_csv(self.config.x_test_data_path)\n",
    "            y_test.to_csv(self.config.y_test_data_path)\n",
    "            x_train.to_csv(self.config.x_train_data_path)\n",
    "\n",
    "            return {\n",
    "                \"trained_model_path\": self.config.trained_model_path,\n",
    "                \"x_test_path\": self.config.x_test_data_path,\n",
    "                \"y_test_path\": self.config.y_test_data_path,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 300, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spati  (None, 300, 100)          0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5080501 (19.38 MB)\n",
      "Trainable params: 5080501 (19.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "249/249 [==============================] - 1158s 5s/step - loss: 0.3408 - accuracy: 0.8648 - val_loss: 0.1909 - val_accuracy: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "try:\n",
    "    config=ConfigurationManager()  \n",
    "    model_trainer_config=config.get_model_trainer_config()\n",
    "    model_trainer=ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer=model_trainer.initiate_model_trainer()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
